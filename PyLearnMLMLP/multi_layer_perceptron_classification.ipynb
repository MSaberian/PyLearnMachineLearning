{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mosaMLP import MLP\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1257, 64), (1257, 10), (540, 64), (540, 10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "Y = digits.target\n",
    "Y = np.eye(10)[Y]  # one hot\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss train: 0.3214392490136027 acc train: 0.1614956245027844\n",
      "loss test: 0.3029619568030171 acc test: 0.2388888888888889\n",
      "loss train: 0.28456653619727906 acc train: 0.3221957040572792\n",
      "loss test: 0.28399377452123936 acc test: 0.3388888888888889\n",
      "loss train: 0.2653022786042209 acc train: 0.4327764518695306\n",
      "loss test: 0.2688898485492673 acc test: 0.40185185185185185\n",
      "loss train: 0.25115348894656153 acc train: 0.5178997613365155\n",
      "loss test: 0.2571452695502465 acc test: 0.4666666666666667\n",
      "loss train: 0.23931508387564313 acc train: 0.5863166268894192\n",
      "loss test: 0.24841387555669583 acc test: 0.5203703703703704\n",
      "loss train: 0.22964045876680064 acc train: 0.6364359586316627\n",
      "loss test: 0.241246838413212 acc test: 0.5592592592592592\n",
      "loss train: 0.22143650227329417 acc train: 0.6610978520286396\n",
      "loss test: 0.23387392716085456 acc test: 0.6111111111111112\n",
      "loss train: 0.2133058227598147 acc train: 0.6913285600636436\n",
      "loss test: 0.227917498708465 acc test: 0.6314814814814815\n",
      "loss train: 0.2059454834282561 acc train: 0.7175815433571997\n",
      "loss test: 0.22234451098626407 acc test: 0.6444444444444445\n",
      "loss train: 0.19909721343725348 acc train: 0.7438345266507558\n",
      "loss test: 0.21724454109462835 acc test: 0.6592592592592592\n",
      "loss train: 0.19270618771238343 acc train: 0.7653142402545744\n",
      "loss test: 0.2125175923577678 acc test: 0.6777777777777778\n",
      "loss train: 0.1867764516223915 acc train: 0.7796340493237868\n",
      "loss test: 0.20788658269076163 acc test: 0.6962962962962963\n",
      "loss train: 0.18108142170477662 acc train: 0.8003182179793158\n",
      "loss test: 0.20339431372574415 acc test: 0.7092592592592593\n",
      "loss train: 0.17564775540452157 acc train: 0.8146380270485283\n",
      "loss test: 0.19958290365133674 acc test: 0.7166666666666667\n",
      "loss train: 0.17053078262443291 acc train: 0.8329355608591885\n",
      "loss test: 0.19636376863394556 acc test: 0.7296296296296296\n",
      "loss train: 0.16587215749465375 acc train: 0.8408910103420844\n",
      "loss test: 0.193256412031628 acc test: 0.7388888888888889\n",
      "loss train: 0.16156986775680907 acc train: 0.8456642800318218\n",
      "loss test: 0.19005370348983872 acc test: 0.7518518518518519\n",
      "loss train: 0.15730085367875096 acc train: 0.8544152744630071\n",
      "loss test: 0.1868474786876356 acc test: 0.7666666666666667\n",
      "loss train: 0.15300884964494377 acc train: 0.8655529037390612\n",
      "loss test: 0.18404380418295116 acc test: 0.7722222222222223\n",
      "loss train: 0.14906860533730557 acc train: 0.8750994431185362\n",
      "loss test: 0.18142044896168347 acc test: 0.7759259259259259\n",
      "loss train: 0.14533141550543632 acc train: 0.8838504375497216\n",
      "loss test: 0.17900602708565228 acc test: 0.7870370370370371\n",
      "loss train: 0.14187202974780222 acc train: 0.8894192521877486\n",
      "loss test: 0.1766853096841479 acc test: 0.7925925925925926\n",
      "loss train: 0.1387127941081958 acc train: 0.8941925218774861\n",
      "loss test: 0.17451264966218785 acc test: 0.7981481481481482\n",
      "loss train: 0.13570016403209736 acc train: 0.9005568814638027\n",
      "loss test: 0.17254884572490126 acc test: 0.8037037037037037\n",
      "loss train: 0.13276328612245697 acc train: 0.9077167859984089\n",
      "loss test: 0.17075235056800261 acc test: 0.8148148148148148\n",
      "loss train: 0.13003999107511094 acc train: 0.9164677804295943\n",
      "loss test: 0.16899568223492933 acc test: 0.8222222222222222\n",
      "loss train: 0.12749626125475577 acc train: 0.9180588703261734\n",
      "loss test: 0.16729187848685037 acc test: 0.8240740740740741\n",
      "loss train: 0.1250832023156781 acc train: 0.9204455051710422\n",
      "loss test: 0.16565911077193263 acc test: 0.8277777777777777\n",
      "loss train: 0.1228276130727108 acc train: 0.92442322991249\n",
      "loss test: 0.1641083613884717 acc test: 0.8296296296296296\n",
      "loss train: 0.12069815139710713 acc train: 0.9307875894988067\n",
      "loss test: 0.16264708761399457 acc test: 0.8277777777777777\n",
      "loss train: 0.11866651642321514 acc train: 0.9323786793953859\n",
      "loss test: 0.16127272021264935 acc test: 0.8314814814814815\n",
      "loss train: 0.11667951752559315 acc train: 0.9323786793953859\n",
      "loss test: 0.15997811415427754 acc test: 0.8351851851851851\n",
      "loss train: 0.11476710499614753 acc train: 0.933969769291965\n",
      "loss test: 0.15875044822066178 acc test: 0.8388888888888889\n",
      "loss train: 0.11290744899356221 acc train: 0.933969769291965\n",
      "loss test: 0.1576192410865237 acc test: 0.8388888888888889\n",
      "loss train: 0.11101038165211956 acc train: 0.9371519490851233\n",
      "loss test: 0.15667577298132723 acc test: 0.8388888888888889\n",
      "loss train: 0.10908056588187902 acc train: 0.9419252187748608\n",
      "loss test: 0.15564733302357878 acc test: 0.8388888888888889\n",
      "loss train: 0.10729323948876443 acc train: 0.94351630867144\n",
      "loss test: 0.15459523255486055 acc test: 0.8425925925925926\n",
      "loss train: 0.10559619635330561 acc train: 0.9443118536197295\n",
      "loss test: 0.15363739118957961 acc test: 0.8462962962962963\n",
      "loss train: 0.10380667458858582 acc train: 0.9466984884645983\n",
      "loss test: 0.15274024698292987 acc test: 0.8462962962962963\n",
      "loss train: 0.10187829748414258 acc train: 0.9482895783611774\n",
      "loss test: 0.15184254513932421 acc test: 0.8481481481481481\n",
      "loss train: 0.10012939845728168 acc train: 0.9506762132060461\n",
      "loss test: 0.15103903612622102 acc test: 0.8481481481481481\n",
      "loss train: 0.09858214340826028 acc train: 0.9522673031026253\n",
      "loss test: 0.15033216266864946 acc test: 0.85\n",
      "loss train: 0.09703851854044541 acc train: 0.954653937947494\n",
      "loss test: 0.149777509253287 acc test: 0.85\n",
      "loss train: 0.0953666698770415 acc train: 0.9554494828957836\n",
      "loss test: 0.14920253766254074 acc test: 0.8518518518518519\n",
      "loss train: 0.09387541014786963 acc train: 0.9554494828957836\n",
      "loss test: 0.14861327556351628 acc test: 0.8518518518518519\n",
      "loss train: 0.0924870011050929 acc train: 0.9562450278440732\n",
      "loss test: 0.14804691059214514 acc test: 0.8518518518518519\n",
      "loss train: 0.09115439832803254 acc train: 0.9578361177406524\n",
      "loss test: 0.14748738042355228 acc test: 0.8537037037037037\n",
      "loss train: 0.08989597933484324 acc train: 0.960222752585521\n",
      "loss test: 0.14692689463266123 acc test: 0.8555555555555555\n",
      "loss train: 0.08870943759812161 acc train: 0.9618138424821002\n",
      "loss test: 0.1463750565029464 acc test: 0.8592592592592593\n",
      "loss train: 0.0875793899423538 acc train: 0.9634049323786794\n",
      "loss test: 0.1458373935943986 acc test: 0.8574074074074074\n",
      "loss train: 0.08649353544499927 acc train: 0.964200477326969\n",
      "loss test: 0.14531682189792933 acc test: 0.8574074074074074\n",
      "loss train: 0.08544058647344706 acc train: 0.964200477326969\n",
      "loss test: 0.14480368354665027 acc test: 0.8592592592592593\n",
      "loss train: 0.08441204493820284 acc train: 0.9649960222752586\n",
      "loss test: 0.1442766135154089 acc test: 0.8611111111111112\n",
      "loss train: 0.08340612241583334 acc train: 0.9665871121718377\n",
      "loss test: 0.1437311505220507 acc test: 0.8629629629629629\n",
      "loss train: 0.08242975274862935 acc train: 0.9673826571201273\n",
      "loss test: 0.1431828815894529 acc test: 0.8666666666666667\n",
      "loss train: 0.08148939472579797 acc train: 0.9689737470167065\n",
      "loss test: 0.14264783664336894 acc test: 0.8666666666666667\n",
      "loss train: 0.08058074699971324 acc train: 0.9697692919649961\n",
      "loss test: 0.14213411467145115 acc test: 0.8648148148148148\n",
      "loss train: 0.0796969276017331 acc train: 0.9697692919649961\n",
      "loss test: 0.14164455416343696 acc test: 0.8648148148148148\n",
      "loss train: 0.07883404599578553 acc train: 0.9697692919649961\n",
      "loss test: 0.1411801645717374 acc test: 0.8648148148148148\n",
      "loss train: 0.07799103177316087 acc train: 0.9705648369132857\n",
      "loss test: 0.14073966684255346 acc test: 0.8648148148148148\n",
      "loss train: 0.07716687991563613 acc train: 0.9721559268098647\n",
      "loss test: 0.1403200043686772 acc test: 0.8648148148148148\n",
      "loss train: 0.07635648228475878 acc train: 0.9721559268098647\n",
      "loss test: 0.13991909603992383 acc test: 0.8685185185185185\n",
      "loss train: 0.07555625062223523 acc train: 0.9729514717581543\n",
      "loss test: 0.13953745562296646 acc test: 0.8685185185185185\n",
      "loss train: 0.07477542808963696 acc train: 0.9729514717581543\n",
      "loss test: 0.13917709354707183 acc test: 0.8685185185185185\n",
      "loss train: 0.07401812438891253 acc train: 0.9729514717581543\n",
      "loss test: 0.13883907251921218 acc test: 0.8685185185185185\n",
      "loss train: 0.07327419524997211 acc train: 0.9729514717581543\n",
      "loss test: 0.13851868549153953 acc test: 0.8685185185185185\n",
      "loss train: 0.07252992685604333 acc train: 0.9729514717581543\n",
      "loss test: 0.1382018158133738 acc test: 0.8703703703703703\n",
      "loss train: 0.07178470295378941 acc train: 0.9745425616547335\n",
      "loss test: 0.13788524187857332 acc test: 0.8703703703703703\n",
      "loss train: 0.07104420079344761 acc train: 0.9745425616547335\n",
      "loss test: 0.13757524196756327 acc test: 0.8703703703703703\n",
      "loss train: 0.07031961192514437 acc train: 0.9745425616547335\n",
      "loss test: 0.1372612890996347 acc test: 0.8685185185185185\n",
      "loss train: 0.06962158517691763 acc train: 0.9745425616547335\n",
      "loss test: 0.13692374975098787 acc test: 0.8685185185185185\n",
      "loss train: 0.06894040934518768 acc train: 0.9753381066030231\n",
      "loss test: 0.1365678041256317 acc test: 0.8685185185185185\n",
      "loss train: 0.06826061620032946 acc train: 0.9761336515513126\n",
      "loss test: 0.13621377999456727 acc test: 0.8685185185185185\n",
      "loss train: 0.06757302210051432 acc train: 0.9761336515513126\n",
      "loss test: 0.1358818462473571 acc test: 0.8685185185185185\n",
      "loss train: 0.06688464576936305 acc train: 0.9769291964996022\n",
      "loss test: 0.13557742862388947 acc test: 0.8685185185185185\n",
      "loss train: 0.06621311290334082 acc train: 0.979315831344471\n",
      "loss test: 0.13529732106709666 acc test: 0.8685185185185185\n",
      "loss train: 0.06556604846229915 acc train: 0.9785202863961814\n",
      "loss test: 0.13503438701599232 acc test: 0.8685185185185185\n",
      "loss train: 0.06493832122036379 acc train: 0.979315831344471\n",
      "loss test: 0.1347850951765933 acc test: 0.8685185185185185\n",
      "loss train: 0.06432332406737234 acc train: 0.979315831344471\n",
      "loss test: 0.1345496543863878 acc test: 0.8685185185185185\n",
      "loss train: 0.06371536941942733 acc train: 0.979315831344471\n",
      "loss test: 0.13433203457596757 acc test: 0.8703703703703703\n",
      "loss train: 0.0631085889656113 acc train: 0.979315831344471\n",
      "loss test: 0.13413775747763884 acc test: 0.8703703703703703\n",
      "loss train: 0.06250259750962227 acc train: 0.9801113762927606\n",
      "loss test: 0.13394274862244226 acc test: 0.8703703703703703\n",
      "loss train: 0.06191261401901804 acc train: 0.9801113762927606\n",
      "loss test: 0.13366763833304432 acc test: 0.8685185185185185\n",
      "loss train: 0.06133393840552515 acc train: 0.9801113762927606\n",
      "loss test: 0.13333364397488404 acc test: 0.8703703703703703\n",
      "loss train: 0.06076501441262673 acc train: 0.9809069212410502\n",
      "loss test: 0.13300462759415818 acc test: 0.8703703703703703\n",
      "loss train: 0.06021594632668035 acc train: 0.9817024661893397\n",
      "loss test: 0.13269240496561135 acc test: 0.8722222222222222\n",
      "loss train: 0.05968608489522369 acc train: 0.9824980111376292\n",
      "loss test: 0.13239377903399763 acc test: 0.8722222222222222\n",
      "loss train: 0.059172557476895156 acc train: 0.9824980111376292\n",
      "loss test: 0.13210445117852043 acc test: 0.8722222222222222\n",
      "loss train: 0.058672745247328184 acc train: 0.9824980111376292\n",
      "loss test: 0.13182014188498622 acc test: 0.8703703703703703\n",
      "loss train: 0.058183941457636175 acc train: 0.9824980111376292\n",
      "loss test: 0.1315366647697037 acc test: 0.8703703703703703\n",
      "loss train: 0.057702996065985675 acc train: 0.9824980111376292\n",
      "loss test: 0.13124988205680885 acc test: 0.8703703703703703\n",
      "loss train: 0.05722600641509552 acc train: 0.9840891010342084\n",
      "loss test: 0.13095612130907366 acc test: 0.8703703703703703\n",
      "loss train: 0.05674857868954022 acc train: 0.9840891010342084\n",
      "loss test: 0.13065407886320593 acc test: 0.8703703703703703\n",
      "loss train: 0.056268842496615866 acc train: 0.9840891010342084\n",
      "loss test: 0.1303482856235855 acc test: 0.8722222222222222\n",
      "loss train: 0.05579360134249958 acc train: 0.9840891010342084\n",
      "loss test: 0.13004881414393388 acc test: 0.8722222222222222\n",
      "loss train: 0.055333108747523285 acc train: 0.9872712808273667\n",
      "loss test: 0.12976248524704914 acc test: 0.8740740740740741\n",
      "loss train: 0.05489007279961199 acc train: 0.9872712808273667\n",
      "loss test: 0.12948730265672814 acc test: 0.8740740740740741\n",
      "loss train: 0.054463804897514 acc train: 0.9888623707239459\n",
      "loss test: 0.1292176761854478 acc test: 0.8740740740740741\n",
      "loss train: 0.05405263865832602 acc train: 0.9888623707239459\n",
      "loss test: 0.1289497052763059 acc test: 0.8740740740740741\n",
      "loss train: 0.05365463887380716 acc train: 0.9888623707239459\n",
      "loss test: 0.12868184347164013 acc test: 0.8759259259259259\n",
      "loss train: 0.053268335094498805 acc train: 0.9888623707239459\n",
      "loss test: 0.12841403739978874 acc test: 0.8759259259259259\n",
      "loss train: 0.052892806612149804 acc train: 0.9888623707239459\n",
      "loss test: 0.1281469929817992 acc test: 0.8759259259259259\n",
      "loss train: 0.05252746780746627 acc train: 0.9888623707239459\n",
      "loss test: 0.12788169361621385 acc test: 0.8759259259259259\n",
      "loss train: 0.052171862022934536 acc train: 0.9888623707239459\n",
      "loss test: 0.1276190528627164 acc test: 0.8759259259259259\n",
      "loss train: 0.05182552269797195 acc train: 0.9888623707239459\n",
      "loss test: 0.12735966282274722 acc test: 0.8777777777777778\n",
      "loss train: 0.05148788151281025 acc train: 0.9888623707239459\n",
      "loss test: 0.12710366653120198 acc test: 0.8777777777777778\n",
      "loss train: 0.05115816961379721 acc train: 0.9888623707239459\n",
      "loss test: 0.12685084523607187 acc test: 0.8796296296296297\n",
      "loss train: 0.05083528080383253 acc train: 0.9888623707239459\n",
      "loss test: 0.12660103101620623 acc test: 0.8814814814814815\n",
      "loss train: 0.05051772255416537 acc train: 0.9888623707239459\n",
      "loss test: 0.12635472199577136 acc test: 0.8814814814814815\n",
      "loss train: 0.05020388371337833 acc train: 0.9888623707239459\n",
      "loss test: 0.12611336775770304 acc test: 0.8814814814814815\n",
      "loss train: 0.049892498915757755 acc train: 0.9896579156722355\n",
      "loss test: 0.12587898864901495 acc test: 0.8814814814814815\n",
      "loss train: 0.04958280575142842 acc train: 0.9896579156722355\n",
      "loss test: 0.12565359363514728 acc test: 0.8833333333333333\n",
      "loss train: 0.049274278749405764 acc train: 0.9896579156722355\n",
      "loss test: 0.12543893541276038 acc test: 0.8833333333333333\n",
      "loss train: 0.04896625872130329 acc train: 0.9904534606205251\n",
      "loss test: 0.12523656229083233 acc test: 0.8851851851851852\n",
      "loss train: 0.04865766387701631 acc train: 0.9904534606205251\n",
      "loss test: 0.12504782658646707 acc test: 0.8851851851851852\n",
      "loss train: 0.04834686316688018 acc train: 0.9904534606205251\n",
      "loss test: 0.12487322638146005 acc test: 0.8870370370370371\n",
      "loss train: 0.0480320343525889 acc train: 0.9904534606205251\n",
      "loss test: 0.12470985746770771 acc test: 0.8870370370370371\n",
      "loss train: 0.04771282051514711 acc train: 0.9904534606205251\n",
      "loss test: 0.12454711248281518 acc test: 0.8870370370370371\n",
      "loss train: 0.0473930334183316 acc train: 0.9904534606205251\n",
      "loss test: 0.1243696677075145 acc test: 0.8888888888888888\n",
      "loss train: 0.0470791691948796 acc train: 0.9904534606205251\n",
      "loss test: 0.12417442904282526 acc test: 0.8888888888888888\n",
      "loss train: 0.04677402561881725 acc train: 0.9904534606205251\n",
      "loss test: 0.12397344137144241 acc test: 0.8888888888888888\n",
      "loss train: 0.04647620879781718 acc train: 0.9904534606205251\n",
      "loss test: 0.12377806145163593 acc test: 0.8888888888888888\n",
      "loss train: 0.04618341435204355 acc train: 0.9904534606205251\n",
      "loss test: 0.12359286234803896 acc test: 0.8888888888888888\n",
      "loss train: 0.045894186064488196 acc train: 0.9912490055688147\n",
      "loss test: 0.12341760656328203 acc test: 0.8888888888888888\n",
      "loss train: 0.04560873892656158 acc train: 0.9912490055688147\n",
      "loss test: 0.12324945832245417 acc test: 0.8888888888888888\n",
      "loss train: 0.04532846051323101 acc train: 0.9920445505171042\n",
      "loss test: 0.12308528818170485 acc test: 0.8888888888888888\n",
      "loss train: 0.04505429646859374 acc train: 0.9920445505171042\n",
      "loss test: 0.12292354241469014 acc test: 0.8888888888888888\n",
      "loss train: 0.04478619331406074 acc train: 0.9928400954653938\n",
      "loss test: 0.1227640468868344 acc test: 0.8888888888888888\n",
      "loss train: 0.044523763258983516 acc train: 0.994431185361973\n",
      "loss test: 0.12260693527303881 acc test: 0.8888888888888888\n",
      "loss train: 0.04426677806824807 acc train: 0.994431185361973\n",
      "loss test: 0.1224520956892583 acc test: 0.8888888888888888\n",
      "loss train: 0.04401520845841805 acc train: 0.9952267303102625\n",
      "loss test: 0.1222990954111085 acc test: 0.8888888888888888\n",
      "loss train: 0.04376908617498509 acc train: 0.9952267303102625\n",
      "loss test: 0.12214727926151159 acc test: 0.8888888888888888\n",
      "loss train: 0.04352837636074425 acc train: 0.9952267303102625\n",
      "loss test: 0.12199590391230221 acc test: 0.8888888888888888\n",
      "loss train: 0.04329292202096121 acc train: 0.9952267303102625\n",
      "loss test: 0.12184425905002591 acc test: 0.8870370370370371\n",
      "loss train: 0.043062449091585846 acc train: 0.9952267303102625\n",
      "loss test: 0.12169176296676101 acc test: 0.8870370370370371\n",
      "loss train: 0.04283659862606515 acc train: 0.9952267303102625\n",
      "loss test: 0.12153804197524522 acc test: 0.8870370370370371\n",
      "loss train: 0.04261496054107525 acc train: 0.9952267303102625\n",
      "loss test: 0.12138300747955343 acc test: 0.8870370370370371\n",
      "loss train: 0.042397096354184205 acc train: 0.9952267303102625\n",
      "loss test: 0.12122692446752 acc test: 0.8870370370370371\n",
      "loss train: 0.042182545757901584 acc train: 0.9952267303102625\n",
      "loss test: 0.12107042154960083 acc test: 0.8870370370370371\n",
      "loss train: 0.041970811796138624 acc train: 0.9952267303102625\n",
      "loss test: 0.12091435369962432 acc test: 0.8888888888888888\n",
      "loss train: 0.04176131188540854 acc train: 0.9952267303102625\n",
      "loss test: 0.12075946944050461 acc test: 0.8907407407407407\n",
      "loss train: 0.041553267485904676 acc train: 0.9952267303102625\n",
      "loss test: 0.12060600717166235 acc test: 0.8944444444444445\n",
      "loss train: 0.04134548410345523 acc train: 0.9952267303102625\n",
      "loss test: 0.12045353189918301 acc test: 0.8944444444444445\n",
      "loss train: 0.0411359668435353 acc train: 0.9952267303102625\n",
      "loss test: 0.12030134638482276 acc test: 0.8944444444444445\n",
      "loss train: 0.04092155357475712 acc train: 0.9952267303102625\n",
      "loss test: 0.12014985385663499 acc test: 0.8962962962962963\n",
      "loss train: 0.04069933952714975 acc train: 0.9952267303102625\n",
      "loss test: 0.12000330205089998 acc test: 0.8962962962962963\n",
      "loss train: 0.040474157626805035 acc train: 0.9952267303102625\n",
      "loss test: 0.11987057220944317 acc test: 0.8962962962962963\n",
      "loss train: 0.04026033836972501 acc train: 0.9952267303102625\n",
      "loss test: 0.1197542206266586 acc test: 0.8962962962962963\n",
      "loss train: 0.04006081067645328 acc train: 0.9952267303102625\n",
      "loss test: 0.11964628934622622 acc test: 0.8962962962962963\n",
      "loss train: 0.039870101971627624 acc train: 0.9960222752585521\n",
      "loss test: 0.11954067602172279 acc test: 0.8962962962962963\n",
      "loss train: 0.03968528544406816 acc train: 0.9960222752585521\n",
      "loss test: 0.11943538905032712 acc test: 0.8962962962962963\n",
      "loss train: 0.039504991398004036 acc train: 0.9960222752585521\n",
      "loss test: 0.11933017602903069 acc test: 0.8962962962962963\n",
      "loss train: 0.039328384013786195 acc train: 0.9960222752585521\n",
      "loss test: 0.11922525133342345 acc test: 0.8981481481481481\n",
      "loss train: 0.03915488058039753 acc train: 0.9960222752585521\n",
      "loss test: 0.11912088505735853 acc test: 0.8962962962962963\n",
      "loss train: 0.03898404861814996 acc train: 0.9960222752585521\n",
      "loss test: 0.11901730196635223 acc test: 0.8962962962962963\n",
      "loss train: 0.0388155543981686 acc train: 0.9960222752585521\n",
      "loss test: 0.11891467095540335 acc test: 0.8962962962962963\n",
      "loss train: 0.03864913254848191 acc train: 0.9960222752585521\n",
      "loss test: 0.11881311645747329 acc test: 0.8962962962962963\n",
      "loss train: 0.03848456699278697 acc train: 0.9960222752585521\n",
      "loss test: 0.11871273279783869 acc test: 0.8962962962962963\n",
      "loss train: 0.03832167905826475 acc train: 0.9960222752585521\n",
      "loss test: 0.11861359713094025 acc test: 0.8981481481481481\n",
      "loss train: 0.03816032069117244 acc train: 0.9960222752585521\n",
      "loss test: 0.1185157804205509 acc test: 0.8981481481481481\n",
      "loss train: 0.0380003716804036 acc train: 0.9960222752585521\n",
      "loss test: 0.11841935644122356 acc test: 0.9\n",
      "loss train: 0.037841740077618286 acc train: 0.9960222752585521\n",
      "loss test: 0.1183244082061971 acc test: 0.9\n",
      "loss train: 0.03768436462982244 acc train: 0.9960222752585521\n",
      "loss test: 0.11823103034732647 acc test: 0.9\n",
      "loss train: 0.03752821700174845 acc train: 0.9960222752585521\n",
      "loss test: 0.11813932547257992 acc test: 0.9\n",
      "loss train: 0.03737330029747126 acc train: 0.9960222752585521\n",
      "loss test: 0.11804939332586285 acc test: 0.9\n",
      "loss train: 0.03721964020478444 acc train: 0.9960222752585521\n",
      "loss test: 0.1179613142645772 acc test: 0.9\n",
      "loss train: 0.03706726772859755 acc train: 0.9960222752585521\n",
      "loss test: 0.11787513220469836 acc test: 0.9\n",
      "loss train: 0.03691619798036422 acc train: 0.9960222752585521\n",
      "loss test: 0.11779084398581278 acc test: 0.9\n",
      "loss train: 0.03676641405304442 acc train: 0.9960222752585521\n",
      "loss test: 0.1177083997993307 acc test: 0.8981481481481481\n",
      "loss train: 0.03661786348275586 acc train: 0.9960222752585521\n",
      "loss test: 0.11762771412764993 acc test: 0.8981481481481481\n",
      "loss train: 0.03647046730941373 acc train: 0.9960222752585521\n",
      "loss test: 0.11754868249579369 acc test: 0.8981481481481481\n",
      "loss train: 0.03632413499367623 acc train: 0.9960222752585521\n",
      "loss test: 0.11747119872304798 acc test: 0.8981481481481481\n",
      "loss train: 0.036178777807071585 acc train: 0.9960222752585521\n",
      "loss test: 0.11739516937489974 acc test: 0.8981481481481481\n",
      "loss train: 0.036034317211167885 acc train: 0.9960222752585521\n",
      "loss test: 0.11732052444258888 acc test: 0.8981481481481481\n",
      "loss train: 0.03589068851681321 acc train: 0.9960222752585521\n",
      "loss test: 0.11724722451730767 acc test: 0.8981481481481481\n",
      "loss train: 0.03574784154250179 acc train: 0.9968178202068417\n",
      "loss test: 0.11717526479438205 acc test: 0.8981481481481481\n",
      "loss train: 0.03560573971220306 acc train: 0.9968178202068417\n",
      "loss test: 0.11710467570541534 acc test: 0.9\n",
      "loss train: 0.03546435834924077 acc train: 0.9968178202068417\n",
      "loss test: 0.11703551948213951 acc test: 0.9\n",
      "loss train: 0.03532368253910822 acc train: 0.9968178202068417\n",
      "loss test: 0.11696788200194307 acc test: 0.9018518518518519\n",
      "loss train: 0.035183704920820964 acc train: 0.9968178202068417\n",
      "loss test: 0.11690186007041113 acc test: 0.9018518518518519\n",
      "loss train: 0.03504442386395836 acc train: 0.9968178202068417\n",
      "loss test: 0.1168375456725102 acc test: 0.9018518518518519\n",
      "loss train: 0.03490584238534821 acc train: 0.9968178202068417\n",
      "loss test: 0.1167750100819239 acc test: 0.9018518518518519\n",
      "loss train: 0.03476796773238354 acc train: 0.9968178202068417\n",
      "loss test: 0.11671429135280709 acc test: 0.9018518518518519\n",
      "loss train: 0.034630811005746685 acc train: 0.9968178202068417\n",
      "loss test: 0.11665538823752511 acc test: 0.9018518518518519\n",
      "loss train: 0.034494385914439665 acc train: 0.9968178202068417\n",
      "loss test: 0.11659826211380984 acc test: 0.9018518518518519\n",
      "loss train: 0.034358706038857385 acc train: 0.9968178202068417\n",
      "loss test: 0.11654284658231488 acc test: 0.9018518518518519\n",
      "loss train: 0.034223780742728305 acc train: 0.9968178202068417\n",
      "loss test: 0.11648906260776089 acc test: 0.9018518518518519\n",
      "loss train: 0.03408961070982335 acc train: 0.9968178202068417\n",
      "loss test: 0.11643683587931632 acc test: 0.9018518518518519\n",
      "loss train: 0.03395618453418596 acc train: 0.9968178202068417\n",
      "loss test: 0.11638611264070263 acc test: 0.9\n",
      "loss train: 0.033823477666925415 acc train: 0.9968178202068417\n",
      "loss test: 0.11633687043037297 acc test: 0.9\n",
      "loss train: 0.03369145444395127 acc train: 0.9968178202068417\n",
      "loss test: 0.11628912060442877 acc test: 0.9\n",
      "loss train: 0.03356007314816376 acc train: 0.9968178202068417\n",
      "loss test: 0.11624290000527997 acc test: 0.9\n",
      "loss train: 0.03342929326106418 acc train: 0.9968178202068417\n",
      "loss test: 0.11619825017720128 acc test: 0.9\n",
      "loss train: 0.03329908327435357 acc train: 0.9968178202068417\n",
      "loss test: 0.11615518533177363 acc test: 0.9\n",
      "loss train: 0.033169426805907884 acc train: 0.9968178202068417\n",
      "loss test: 0.11611365573487685 acc test: 0.9\n",
      "loss train: 0.03304032476042119 acc train: 0.9968178202068417\n",
      "loss test: 0.11607351971540676 acc test: 0.9\n",
      "loss train: 0.03291179245114477 acc train: 0.9976133651551312\n",
      "loss test: 0.11603453965568684 acc test: 0.9\n",
      "loss train: 0.03278385280957563 acc train: 0.9976133651551312\n",
      "loss test: 0.11599640937541991 acc test: 0.9\n",
      "loss train: 0.03265652867950245 acc train: 0.9976133651551312\n",
      "loss test: 0.1159588041804791 acc test: 0.9\n",
      "loss train: 0.03252983713993913 acc train: 0.9976133651551312\n",
      "loss test: 0.11592143232007847 acc test: 0.9\n",
      "train completed!\n"
     ]
    }
   ],
   "source": [
    "MLPstructure = edict(\n",
    "    D_in = X_train.shape[1],\n",
    "    H1 = 128,\n",
    "    H2 = 32,\n",
    "    D_out = Y_train.shape[1],\n",
    "    Î· = 0.001,\n",
    ")\n",
    "\n",
    "model = MLP(MLPstructure)\n",
    "train_output = model.fit(X_train, Y_train, X_test, Y_test, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"input/test4.png\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image = image.astype(np.float32)\n",
    "\n",
    "x = image.reshape(-1, 1)\n",
    "y_pred = model.predict(x)\n",
    "print(np.argmax(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., 14., 13.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 15., 15.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 14., 15.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 14., 15.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 13., 15.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 13., 16.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., 13., 16.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  9., 15.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
